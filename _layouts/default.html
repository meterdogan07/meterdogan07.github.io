<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-E00L9PT3V9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-E00L9PT3V9');
  </script>

  <title>{{ site.name }}</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">

        <!-- Header / About -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Mete Erdogan
              </h1>
          
              <p>
                I am a first-year PhD student in Electrical Engineering at <b>Stanford University</b>, 
                currently rotating with <b>Mert Pilanci</b> and <b>Chris Ré</b>. My research focuses on the 
                theoretical and algorithmic foundations of efficient, large-scale learning systems.
              </p>
          
              <p>
                I am particularly interested in <b>LLM compression</b>, <b>efficient sequence modeling</b>,
                and <b>alternative learning rules</b> that reduce memory, compute, or optimization overhead.
                My work explores how structure in optimization, information theory, and signal processing can be leveraged
                to design scalable and adaptive learning mechanisms.
              </p>
          
              <p>
                Before Stanford, I worked at <b>EPFL</b> with 
                <b>Volkan Cevher</b> on language model pruning, compression, and spectral interpretability 
                (e.g., PCA/CCA), and non-Euclidean optimization methods for deep learning. 
                I completed dual B.S. degrees in Electrical and Electronics Engineering and Computer Science 
                at <b>Koç University</b>, where I worked with <b>Alper T. Erdogan</b> on deep learning theory and 
                biologically plausible learning rules alternative to backpropagation. I also collaborated with 
                <b>Deniz Yuret</b> on developing Turkish language models, 
                with <b>Metin Sitti</b> at the Max Planck Institute on learning-based modeling and control, 
                and with <b>Alper Demir</b> on Kalman filtering for sensor tracking.
              </p>
          
              <p style="text-align:center">
                <a href="mailto:merdogan@stanford.edu">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/meterdogan07">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=h2nJVBgAAAAJ&hl=tr">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/meteerdogan/">LinkedIn</a>
              </p>
            </td>
          
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo"
                src="https://media.licdn.com/dms/image/v2/D4D03AQFpRLGeZ0pq0g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1719327591661?e=1772668800&v=beta&t=NXO4aGEsaIQNau9RVOO3OGU-fqNiXT_YwCYNAYyoDTw">
            </td>
          </tr>
        </table>

        <!-- Research Intro -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I’m broadly interested in efficient learning and sequence modeling. Current themes include:
                (i) Efficient attention/memory mechanisms for long context,
                (ii) Model compression for LLMs and VLMs,
                and (iii) Convex/Non-Convex Optimization.
              </p>
            </td>
          </tr>
        </table>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Publications</h2>
        
              <ul style="padding-left:18px; margin-top:10px;">
                <li style="margin-bottom:10px;">
                  <b>Efficient Large Language Model Inference with Neural Block Linearization</b><br/>
                  <span>Mete Erdogan, Francesco Tonin, Volkan Cevher.</span><br/>
                  <em>NeurIPS 2025 (Main Track)</em>.
                  <a href="https://arxiv.org/abs/2505.21077">arXiv</a>
                  <!-- / <a href="#">pdf</a> / <a href="#">code</a> -->
                </li>
        
                <li style="margin-bottom:10px;">
                  <b>Generalized Gradient Norm Clipping &amp; Non-Euclidean (L0,L1)-Smoothness</b><br/>
                  <span>T. Pethick, W. Xie, Mete Erdogan, K. Antonakopoulos, T. Silveti-Falls, Volkan Cevher.</span><br/>
                  <em>NeurIPS 2025 <span style="color:#b30000;"><b>(Oral)</b></span></em>.
                  <a href="https://arxiv.org/abs/2506.01913">arXiv</a>
                </li>
        
                <li style="margin-bottom:10px;">
                  <b>Error Broadcast and Decorrelation as a Potential Artificial and Natural Learning Mechanism</b><br/>
                  <span>Mete Erdogan, Cengiz Pehlevan, Alper T. Erdogan.</span><br/>
                  <em>NeurIPS 2025 <span style="color:#b30000;"><b>(Spotlight)</b></span></em>.
                  <a href="https://arxiv.org/abs/2504.11558">arXiv</a>
                </li>
        
                <li style="margin-bottom:10px;">
                  <b>Bridging the Bosphorus: Leveraging Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking</b><br/>
                  <span>E. Acikgoz, Mete Erdogan, Deniz Yuret.</span><br/>
                  <em>EMNLP 2024 MRL Workshop</em>.
                  <a href="https://arxiv.org/abs/2405.04685">arXiv</a>
                </li>
        
                <li style="margin-bottom:10px;">
                  <b>Machine Learning and Kalman Filtering for Nanomechanical Mass Spectrometry</b><br/>
                  <span>Mete Erdogan, N. B. Baytekin, S. E. Coban, Alper Demir.</span><br/>
                  <em>IEEE Sensors Journal (2024)</em>.
                  <a href="https://ieeexplore.ieee.org/abstract/document/10399336">IEEE</a>
                </li>
              </ul>
            </td>
          </tr>    
        </table>

        <style>
          .edu-logo-td { width: 170px; }  /* controls how far the text starts */
          .logo-box{
            width: 140px;
            height: 70px;
            display:flex;
            align-items:center;
            justify-content:center;
          }
          .logo-box img{
            max-width:100%;
            max-height:100%;
            object-fit:contain;
            display:block;
          }
        </style>
        
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
              <td>
                <h2>Education</h2>
              </td>
            </tr>
          <tbody>
            <tr>
              <td class="edu-logo-td" style="padding:20px;vertical-align:middle;">
                <div class="logo-box">
                  <img src="https://dorm2dorm.com/wp-content/uploads/2024/10/stanford-university-logo.png" alt="Stanford logo">
                </div>
              </td>
              <td style="padding:20px;vertical-align:middle;">
                <div>PhD Student in Electrical Engineering</div>
                <div>Stanford University (2025–Present)</div>
              </td>
            </tr>
        
            <tr>
              <td class="edu-logo-td" style="padding:20px;vertical-align:middle;">
                <div class="logo-box">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/9/95/Logo_EPFL_2019.svg" alt="EPFL logo">
                </div>
              </td>
              <td style="padding:20px;vertical-align:middle;">
                <div>Master's Valorization Program - Research Intern</div>
                <div>EPFL (2024–2025)</div>
              </td>
            </tr>
        
            <tr>
              <td class="edu-logo-td" style="padding:20px;vertical-align:middle;">
                <div class="logo-box">
                  <img src="https://upload.wikimedia.org/wikipedia/en/2/24/Ko%C3%A7_University_logo.svg" alt="Koç University logo">
                </div>
              </td>
              <td style="padding:20px;vertical-align:middle;">
                <div>B.Sc. Electrical & Electronics Engineering + Computer Science</div>
                <div>Koç University (2019–2024)</div>
              </td>
            </tr>
          </tbody>
        </table>

      </td>
    </tr>
  </table>
</body>

</html>
